{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6656fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c1ef6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"/home/jiaxingliu/workspace/swe-pdb/rllm/data/rl_1125.parquets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9720c18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[0].to_json('test.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6537046b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': \"from solution import *\\n\\nimport math\\n\\nfrom solution import *\\n\\nimport math\\n\\nfrom solution import *\\n\\nimport math\\n\\nfrom solution import display_board, is_winner, is_draw, make_move\\n\\ndef test_display_board():\\n    board = [['-' for _ in range(5)] for _ in range(5)]\\n    # This is a visual test, make sure the output looks like a 5x5 grid with '-'\\n    display_board(board)\\n\\ndef test_is_winner_horizontal():\\n    board = [\\n        ['X', 'X', 'X', 'X', 'X'],\\n        ['-', '-', '-', '-', '-'],\\n        ['-', '-', '-', '-', '-'],\\n        ['-', '-', '-', '-', '-'],\\n        ['-', '-', '-', '-', '-'],\\n    ]\\n    assert is_winner(board, 'X')\\n\\ndef test_is_winner_vertical():\\n    board = [\\n        ['O', '-', '-', '-', '-'],\\n        ['O', '-', '-', '-', '-'],\\n        ['O', '-', '-', '-', '-'],\\n        ['O', '-', '-', '-', '-'],\\n        ['O', '-', '-', '-', '-'],\\n    ]\\n    assert is_winner(board, 'O')\\n\\ndef test_is_winner_diagonal():\\n    board = [\\n        ['X', '-', '-', '-', '-'],\\n        ['-', 'X', '-', '-', '-'],\\n        ['-', '-', 'X', '-', '-'],\\n        ['-', '-', '-', 'X', '-'],\\n        ['-', '-', '-', '-', 'X'],\\n    ]\\n    assert is_winner(board, 'X')\\n\\ndef test_not_winner_incomplete_line():\\n    board = [\\n        ['X', 'X', 'X', 'X', '-'],\\n        ['-', '-', '-', '-', '-'],\\n        ['-', '-', '-', '-', '-'],\\n        ['-', '-', '-', '-', '-'],\\n        ['-', '-', '-', '-', '-'],\\n    ]\\n    assert not is_winner(board, 'X')\\n\\ndef test_is_draw():\\n    board = [\\n        ['X', 'O', 'X', 'O', 'X'],\\n        ['O', 'X', 'O', 'X', 'O'],\\n        ['X', 'O', 'X', 'O', 'X'],\\n        ['O', 'X', 'O', 'X', 'O'],\\n        ['X', 'O', 'X', 'O', 'X'],\\n    ]\\n    assert is_draw(board)\\n\\ndef test_not_draw_still_empty_cells():\\n    board = [\\n        ['X', 'O', 'X', 'O', 'X'],\\n        ['O', 'X', 'O', 'X', 'O'],\\n        ['X', 'O', 'X', 'O', 'X'],\\n        ['O', 'X', '-', 'X', 'O'],\\n        ['X', 'O', 'X', 'O', 'X'],\\n    ]\\n    assert not is_draw(board)\\n\\ndef test_make_move_success():\\n    board = [['-' for _ in range(5)] for _ in range(5)]\\n    assert make_move(board, 0, 0, 'X')\\n    assert board[0][0] == 'X'\\n\\ndef test_make_move_fail():\\n    board = [['-' for _ in range(5)] for _ in range(5)]\\n    make_move(board, 0, 0, 'X')\\n    assert not make_move(board, 0, 0, 'O')  # Already occupied\\n    assert board[0][0] == 'X'\",\n",
       " 'path': 'test.py'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0].get('extra_info')['files'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "681304fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|im_start|>assistant\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/data/jiaxingliu/checkpoints/qwen3-14b/step300/huggingface\")\n",
    "tokenizer.apply_chat_template(df.iloc[0][\"prompt\"], add_generation_prompt=True, tokenize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8ce93f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e72fb78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{%- if tools %}\n",
      "    {{- '<|im_start|>system\\n' }}\n",
      "    {%- if messages[0].role == 'system' %}\n",
      "        {{- messages[0].content + '\\n\\n' }}\n",
      "    {%- endif %}\n",
      "    {{- \"# Tools\\n\\nYou may call one or more functions to assist with the user query.\\n\\nYou are provided with function signatures within <tools></tools> XML tags:\\n<tools>\" }}\n",
      "    {%- for tool in tools %}\n",
      "        {{- \"\\n\" }}\n",
      "        {{- tool | tojson }}\n",
      "    {%- endfor %}\n",
      "    {{- \"\\n</tools>\\n\\nFor each function call, return a json object with function name and arguments within <tool_call></tool_call> XML tags:\\n<tool_call>\\n{\\\"name\\\": <function-name>, \\\"arguments\\\": <args-json-object>}\\n</tool_call><|im_end|>\\n\" }}\n",
      "{%- else %}\n",
      "    {%- if messages[0].role == 'system' %}\n",
      "        {{- '<|im_start|>system\\n' + messages[0].content + '<|im_end|>\\n' }}\n",
      "    {%- endif %}\n",
      "{%- endif %}\n",
      "{%- set ns = namespace(multi_step_tool=true, last_query_index=messages|length - 1) %}\n",
      "{%- for message in messages[::-1] %}\n",
      "    {%- set index = (messages|length - 1) - loop.index0 %}\n",
      "    {%- if ns.multi_step_tool and message.role == \"user\" and message.content is string and not(message.content.startswith('<tool_response>') and message.content.endswith('</tool_response>')) %}\n",
      "        {%- set ns.multi_step_tool = false %}\n",
      "        {%- set ns.last_query_index = index %}\n",
      "    {%- endif %}\n",
      "{%- endfor %}\n",
      "{%- for message in messages %}\n",
      "    {%- if message.content is string %}\n",
      "        {%- set content = message.content %}\n",
      "    {%- else %}\n",
      "        {%- set content = '' %}\n",
      "    {%- endif %}\n",
      "    {%- if (message.role == \"user\") or (message.role == \"system\" and not loop.first) %}\n",
      "        {{- '<|im_start|>' + message.role + '\\n' + content + '<|im_end|>' + '\\n' }}\n",
      "    {%- elif message.role == \"assistant\" %}\n",
      "        {%- set reasoning_content = '' %}\n",
      "        {%- if message.reasoning_content is string %}\n",
      "            {%- set reasoning_content = message.reasoning_content %}\n",
      "        {%- else %}\n",
      "            {%- if '</think>' in content %}\n",
      "                {%- set reasoning_content = content.split('</think>')[0].rstrip('\\n').split('<think>')[-1].lstrip('\\n') %}\n",
      "                {%- set content = content.split('</think>')[-1].lstrip('\\n') %}\n",
      "            {%- endif %}\n",
      "        {%- endif %}\n",
      "        {%- if loop.index0 > ns.last_query_index %}\n",
      "            {%- if loop.last or (not loop.last and reasoning_content) %}\n",
      "                {{- '<|im_start|>' + message.role + '\\n<think>\\n' + reasoning_content.strip('\\n') + '\\n</think>\\n\\n' + content.lstrip('\\n') }}\n",
      "            {%- else %}\n",
      "                {{- '<|im_start|>' + message.role + '\\n' + content }}\n",
      "            {%- endif %}\n",
      "        {%- else %}\n",
      "            {{- '<|im_start|>' + message.role + '\\n' + content }}\n",
      "        {%- endif %}\n",
      "        {%- if message.tool_calls %}\n",
      "            {%- for tool_call in message.tool_calls %}\n",
      "                {%- if (loop.first and content) or (not loop.first) %}\n",
      "                    {{- '\\n' }}\n",
      "                {%- endif %}\n",
      "                {%- if tool_call.function %}\n",
      "                    {%- set tool_call = tool_call.function %}\n",
      "                {%- endif %}\n",
      "                {{- '<tool_call>\\n{\"name\": \"' }}\n",
      "                {{- tool_call.name }}\n",
      "                {{- '\", \"arguments\": ' }}\n",
      "                {%- if tool_call.arguments is string %}\n",
      "                    {{- tool_call.arguments }}\n",
      "                {%- else %}\n",
      "                    {{- tool_call.arguments | tojson }}\n",
      "                {%- endif %}\n",
      "                {{- '}\\n</tool_call>' }}\n",
      "            {%- endfor %}\n",
      "        {%- endif %}\n",
      "        {{- '<|im_end|>\\n' }}\n",
      "    {%- elif message.role == \"tool\" %}\n",
      "        {%- if loop.first or (messages[loop.index0 - 1].role != \"tool\") %}\n",
      "            {{- '<|im_start|>user' }}\n",
      "        {%- endif %}\n",
      "        {{- '\\n<tool_response>\\n' }}\n",
      "        {{- content }}\n",
      "        {{- '\\n</tool_response>' }}\n",
      "        {%- if loop.last or (messages[loop.index0 + 1].role != \"tool\") %}\n",
      "            {{- '<|im_end|>\\n' }}\n",
      "        {%- endif %}\n",
      "    {%- endif %}\n",
      "{%- endfor %}\n",
      "{%- if add_generation_prompt %}\n",
      "    {{- '<|im_start|>assistant\\n' }}\n",
      "    {%- if enable_thinking is defined and enable_thinking is false %}\n",
      "        {{- '<think>\\n\\n</think>\\n\\n' }}\n",
      "    {%- endif %}\n",
      "{%- endif %}\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.chat_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93c78146",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"run_tests\",\n",
    "            \"description\": \"运行项目测试套件并返回失败详情\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"command\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"完整测试命令，例如 `pytest tests/`\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"command\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"git_apply_patch\",\n",
    "            \"description\": \"将补丁内容应用到仓库\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"patch\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"标准 unified diff 文本\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"patch\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"你是经验丰富的软件调试代理，请按步骤修复问题。\"},\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"项目里的 `tests/test_math.py` 有用例挂了，先把失败原因找出来。\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": '<tool_call name=\"run_tests\">{\"command\": \"pytest tests/test_math.py\"}</tool_call>'\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"tool\",\n",
    "        \"name\": \"run_tests\",\n",
    "        \"content\": \"FAIL test_division_zero ... ZeroDivisionError: division by zero\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"测试在除零逻辑上崩了，我需要改 `math_utils.py`，请给我补丁。\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"好的，修复完要重新跑一次测试确认。\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d51f261f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "你是经验丰富的软件调试代理，请按步骤修复问题。\n",
      "\n",
      "# Tools\n",
      "\n",
      "You may call one or more functions to assist with the user query.\n",
      "\n",
      "You are provided with function signatures within <tools></tools> XML tags:\n",
      "<tools>\n",
      "{\"type\": \"function\", \"function\": {\"name\": \"run_tests\", \"description\": \"运行项目测试套件并返回失败详情\", \"parameters\": {\"type\": \"object\", \"properties\": {\"command\": {\"type\": \"string\", \"description\": \"完整测试命令，例如 `pytest tests/`\"}}, \"required\": [\"command\"]}}}\n",
      "{\"type\": \"function\", \"function\": {\"name\": \"git_apply_patch\", \"description\": \"将补丁内容应用到仓库\", \"parameters\": {\"type\": \"object\", \"properties\": {\"patch\": {\"type\": \"string\", \"description\": \"标准 unified diff 文本\"}}, \"required\": [\"patch\"]}}}\n",
      "</tools>\n",
      "\n",
      "For each function call, return a json object with function name and arguments within <tool_call></tool_call> XML tags:\n",
      "<tool_call>\n",
      "{\"name\": <function-name>, \"arguments\": <args-json-object>}\n",
      "</tool_call><|im_end|>\n",
      "<|im_start|>user\n",
      "项目里的 `tests/test_math.py` 有用例挂了，先把失败原因找出来。<|im_end|>\n",
      "<|im_start|>assistant\n",
      "<tool_call name=\"run_tests\">{\"command\": \"pytest tests/test_math.py\"}</tool_call><|im_end|>\n",
      "<|im_start|>user\n",
      "<tool_response>\n",
      "FAIL test_division_zero ... ZeroDivisionError: division by zero\n",
      "</tool_response><|im_end|>\n",
      "<|im_start|>assistant\n",
      "测试在除零逻辑上崩了，我需要改 `math_utils.py`，请给我补丁。<|im_end|>\n",
      "<|im_start|>user\n",
      "好的，修复完要重新跑一次测试确认。<|im_end|>\n",
      "<|im_start|>assistant\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.apply_chat_template(messages,tools,add_generation_prompt=True, tokenize=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0c6716",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "r2llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
