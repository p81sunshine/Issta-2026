#!/usr/bin/env python3
"""
Debug-Gym Agentç«¯åˆ°ç«¯æµ‹è¯•ï¼ˆå¯ç›´æ¥è¿è¡Œï¼‰

ä½¿ç”¨çœŸå®çš„DebugGymAgentã€SWE-benchç¯å¢ƒå’ŒNvidia APIè¿›è¡Œå®Œæ•´æµ‹è¯•ã€‚

æµ‹è¯•æµç¨‹ï¼š
1. åˆå§‹åŒ–Nvidia LLM
2. åˆ›å»ºSWE-benchç¯å¢ƒï¼ˆK8såç«¯ï¼‰
3. åˆ›å»ºDebugGymAgent
4. è¿è¡ŒAgent-Environmentäº¤äº’å¾ªç¯
5. éªŒè¯æ‰€æœ‰å·¥å…·ï¼ˆpdb, eval, view, grep, rewrite, listdirï¼‰
"""
import json
import logging
import os
import sys
import traceback

from openai import OpenAI

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def check_dependencies():
    """æ£€æŸ¥æ‰€éœ€ä¾èµ–"""
    logger.info("="*60)
    logger.info("æ£€æŸ¥ä¾èµ–")
    logger.info("="*60)
    
    missing = []
    
    try:
        from kubernetes import client, config
        logger.info("âœ“ Kubernetes client")
    except ImportError:
        missing.append("kubernetes")
    
    try:
        from rllm.environments.swe.swe import SWEEnv
        logger.info("âœ“ SWEBenchDebugGymEnv")
    except ImportError:
        missing.append("rllm.environments.debug_gym")
    
    try:
        from rllm.agents.swe_agent import SWEAgent
        logger.info("âœ“ DebugGymAgent")
    except ImportError:
        missing.append("rllm.agents.debug_gym_agent")
    
    try:
        from debug_gym.gym.envs.swe_bench import SWEBenchEnv
        logger.info("âœ“ Debug-Gym SWE-bench")
    except ImportError:
        missing.append("debug-gym")
    
    if missing:
        logger.error(f"âŒ Missing: {', '.join(missing)}")
        return False
    
    return True


class NvidiaLLM:
    """
    Nvidia API LLMåŒ…è£…å™¨ã€‚
    
    å…¼å®¹chat completions APIï¼Œæ”¯æŒæµå¼å“åº”ã€‚
    """
    
    def __init__(
        self,
        api_key: str = "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",
        model: str = "qwen/qwen3-next-80b-a3b-instruct",
        temperature: float = 0.7,
        top_p: float = 0.9,
        max_tokens: int = 2048,
        stream: bool = True,
    ):
        self.client = OpenAI(
            base_url="https://integrate.api.nvidia.com/v1",
            api_key=api_key
        )
        self.model = model
        self.temperature = temperature
        self.top_p = top_p
        self.max_tokens = max_tokens
        self.stream = stream
        self.call_count = 0
    
    def __call__(self, messages, **kwargs):
        """å…¼å®¹LLMè°ƒç”¨æ¥å£"""
        return self.generate(messages, **kwargs)
    
    def generate(self, messages, **kwargs):
        """ç”ŸæˆLLMå“åº”"""
        self.call_count += 1
        
        # æ˜¾ç¤ºæœ€åä¸€æ¡ç”¨æˆ·æ¶ˆæ¯
        if messages and messages[-1].get("role") == "user":
            last_msg = messages[-1]["content"]
            logger.info(f"  æœ€åè§‚å¯Ÿ: {last_msg}...")
        
        try:
            completion = self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                temperature=self.temperature,
                top_p=self.top_p,
                max_tokens=self.max_tokens,
                stream=self.stream,
                **kwargs
            )
            
            if self.stream:
                # æ”¶é›†æµå¼å“åº”
                response_text = ""
                print("  ğŸ“ å“åº”: ", end="", flush=True)
                for chunk in completion:
                    if chunk.choices[0].delta.content:
                        content = chunk.choices[0].delta.content
                        response_text += content
                        print(content, end="", flush=True)
                print()  # æ¢è¡Œ
            else:
                response_text = completion.choices[0].message.content
                print(f"  ğŸ“ å“åº”: {response_text}")
            
            logger.info(f"  âœ“ å“åº”é•¿åº¦: {len(response_text)} chars")
            return response_text
            
        except Exception as e:
            logger.error(f"âŒ LLMè°ƒç”¨å¤±è´¥: {e}")
            traceback.print_exc()
            raise


def test_agent_with_real_env():
    """ä½¿ç”¨çœŸå®Agentã€ç¯å¢ƒå’ŒLLMçš„ç«¯åˆ°ç«¯æµ‹è¯•"""
    logger.info("\n" + "ğŸš€"*30)
    logger.info("Debug-Gym Agentç«¯åˆ°ç«¯æµ‹è¯•")
    logger.info("ğŸš€"*30 + "\n")
    
    env = None
    agent = None
    
    try:
        # 1. åˆ›å»ºLLM
        logger.info("="*60)
        logger.info("æ­¥éª¤1: åˆå§‹åŒ–Nvidia LLM")
        logger.info("="*60)
        
        llm = NvidiaLLM(
            model="qwen/qwen3-next-80b-a3b-instruct",
            temperature=0.7,
            top_p=0.9,
            max_tokens=2048,
            stream=True,
        )
        logger.info(f"âœ“ LLMåˆå§‹åŒ–å®Œæˆ: {llm.model}")
        
        # 2. åˆ›å»ºç¯å¢ƒ
        logger.info("\n" + "="*60)
        logger.info("æ­¥éª¤2: åˆ›å»ºSWE-benchç¯å¢ƒï¼ˆK8såç«¯ï¼‰")
        logger.info("="*60)
        
        from rllm.environments.debug_gym.swe_bench_env import SWEBenchDebugGymEnv
        
        env = SWEBenchDebugGymEnv(
            backend="kubernetes",
            dataset_id="princeton-nlp/SWE-bench_Lite",
            split="test",
            instance_id="astropy__astropy-7746",  # ç®€å•å®ä¾‹
            max_steps=10,  # é™åˆ¶æ­¥æ•°
            enable_pdb=True,  # å¯ç”¨PDBï¼ˆK8sæ”¯æŒTTYï¼‰
            enable_bash=True,
            enable_grep=True,
            k8s_namespace="default",
            k8s_pip_mirror="https://mirrors.zju.edu.cn/pypi/web/simple",
            k8s_apt_mirror="mirrors.zju.edu.cn",
            logger_name="agent-e2e-test",
        )
        
        logger.info(f"âœ“ ç¯å¢ƒåˆ›å»ºå®Œæˆ")
        logger.info(f"  Backend: {env.backend}")
        logger.info(f"  Instance: {env.instance_id}")
        
        # 3. åˆ›å»ºAgent
        logger.info("\n" + "="*60)
        logger.info("æ­¥éª¤3: åˆ›å»ºDebugGymAgent")
        logger.info("="*60)
        
        from rllm.agents.debug_gym_agent import DebugGymAgent
        
        agent = DebugGymAgent(
            use_fn_calling=False,
            format_model_response=False,
        )
        
        logger.info("âœ“ Agentåˆ›å»ºå®Œæˆ")
        
        # 4. Resetç¯å¢ƒ
        logger.info("\n" + "="*60)
        logger.info("æ­¥éª¤4: Resetç¯å¢ƒ")
        logger.info("="*60)
        
        breakpoint()
        obs, info = env.reset()
        logger.info(f"âœ“ ç¯å¢ƒé‡ç½®å®Œæˆ")
        logger.info(f"  Instance: {info.get('instance_id')}")
        logger.info(f"  Repository: {info.get('repo')}")
        logger.info(f"  åˆå§‹å¾—åˆ†: {info.get('score')}/{info.get('max_score')}")
        logger.info(f"  è§‚å¯Ÿé•¿åº¦: {len(obs)} chars")
        
        # åˆå§‹åŒ–agent
        agent.reset()
        agent.update_from_env(obs, 0.0, False, info)
        
        # 5. è¿è¡Œå¤šæ­¥äº¤äº’
        logger.info("\n" + "="*60)
        logger.info("æ­¥éª¤5: Agent-Environmentäº¤äº’å¾ªç¯")
        logger.info("="*60)
        
        max_steps = 5  # é™åˆ¶æµ‹è¯•æ­¥æ•°
        total_reward = 0
        
        for step in range(max_steps):
            logger.info(f"\n{'â”€'*60}")
            logger.info(f"æ­¥éª¤ {step + 1}/{max_steps}")
            logger.info(f"{'â”€'*60}")
            
            # 5.1 LLMç”Ÿæˆå“åº”
            logger.info("ğŸ“ ç”ŸæˆåŠ¨ä½œ...")
            messages = agent.chat_completions
            logger.info(f"  Prompt: {json.dumps(messages, indent=2)}")
            breakpoint()
            
            try:
                response = llm.generate(messages)
                logger.info(f"  âœ“ LLMå“åº”ç”Ÿæˆ")
            except Exception as e:
                logger.error(f"  âŒ LLMç”Ÿæˆå¤±è´¥: {e}")
                break
            
            logger.info(f"  Response: {response}")
            # 5.2 Agentå¤„ç†å“åº”
            logger.info("ğŸ”§ å¤„ç†å“åº”...")
            try:
                action = agent.update_from_model(response)
                action_str = action.action
                logger.info(f"  âœ“ åŠ¨ä½œ: {action_str}")
            except Exception as e:
                logger.error(f"  âŒ åŠ¨ä½œå¤„ç†å¤±è´¥: {e}")
                break
            
            breakpoint()
            # 5.3 ç¯å¢ƒæ‰§è¡ŒåŠ¨ä½œ
            logger.info("âš™ï¸  æ‰§è¡ŒåŠ¨ä½œ...")
            try:
                obs, reward, done, truncated, info = env.step(action_str)
                total_reward += reward
                
                logger.info(f"  âœ“ åŠ¨ä½œæ‰§è¡Œå®Œæˆ")
                logger.info(f"  å¥–åŠ±: {reward}")
                logger.info(f"  å¾—åˆ†: {info.get('score')}/{info.get('max_score')}")
                logger.info(f"  å®Œæˆ: done={done}, truncated={truncated}")
                logger.info(f"  è§‚å¯Ÿ: {str(obs)[:200]}...")
                
            except Exception as e:
                logger.error(f"  âŒ åŠ¨ä½œæ‰§è¡Œå¤±è´¥: {e}")
                traceback.print_exc()
                break
            
            # 5.4 æ›´æ–°Agent
            agent.update_from_env(obs, reward, done, info)
            
            # æ£€æŸ¥æ˜¯å¦å®Œæˆ
            if done or truncated:
                logger.info(f"\nğŸ¯ Episodeå®Œæˆ: {'ä»»åŠ¡æˆåŠŸ' if done else 'è¾¾åˆ°æœ€å¤§æ­¥æ•°'}")
                break
        
        # 6. è®¡ç®—æœ€ç»ˆå¥–åŠ±
        logger.info("\n" + "="*60)
        logger.info("æ­¥éª¤6: è®¡ç®—æœ€ç»ˆå¥–åŠ±")
        logger.info("="*60)
        
        final_reward = env.compute_final_reward()
        logger.info(f"âœ“ æœ€ç»ˆå¥–åŠ±: {final_reward}")
        logger.info(f"  ç´¯ç§¯å¥–åŠ±: {total_reward}")
        logger.info(f"  è½¨è¿¹æ­¥æ•°: {len(agent.trajectory.steps)}")
        
        # 7. æ¸…ç†
        logger.info("\n" + "="*60)
        logger.info("æ­¥éª¤7: æ¸…ç†èµ„æº")
        logger.info("="*60)
        
        env.close()
        logger.info("âœ“ ç¯å¢ƒå·²å…³é—­")
        
        # æ€»ç»“
        print("\n" + "="*60)
        print("æµ‹è¯•æ€»ç»“")
        print("="*60)
        print(f"  LLMè°ƒç”¨æ¬¡æ•°: {llm.call_count}")
        print(f"  æ‰§è¡Œæ­¥æ•°: {len(agent.trajectory.steps)}")
        print(f"  ç´¯ç§¯å¥–åŠ±: {total_reward}")
        print(f"  æœ€ç»ˆå¥–åŠ±: {final_reward}")
        print(f"  æœ€ç»ˆå¾—åˆ†: {info.get('score')}/{info.get('max_score')}")
        print("="*60)
        print("âœ… ç«¯åˆ°ç«¯æµ‹è¯•å®Œæˆï¼")
        print("="*60)
        
        return True
        
    except Exception as e:
        logger.error(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        traceback.print_exc()
        
        if env:
            try:
                env.close()
            except:
                pass
        
        return False


def main():
    """ä¸»å‡½æ•°"""
    print("\n" + "ğŸ¯"*30)
    print("Debug-Gym + rLLM + K8s + Nvidia API")
    print("ç«¯åˆ°ç«¯é›†æˆæµ‹è¯•")
    print("ğŸ¯"*30 + "\n")
    
    # æ£€æŸ¥ä¾èµ–
    if not check_dependencies():
        return False
    
    # æ£€æŸ¥K8sè¿æ¥
    logger.info("\n" + "="*60)
    logger.info("æ£€æŸ¥Kubernetesè¿æ¥")
    logger.info("="*60)
    
    try:
        import subprocess
        result = subprocess.run(
            ["kubectl", "cluster-info"],
            capture_output=True,
            timeout=10
        )
        if result.returncode == 0:
            logger.info("âœ“ Kubernetesé›†ç¾¤å¯ç”¨")
        else:
            logger.error("âŒ æ— æ³•è¿æ¥Kubernetesé›†ç¾¤")
            return False
    except Exception as e:
        logger.error(f"âŒ K8sè¿æ¥æ£€æŸ¥å¤±è´¥: {e}")
        return False
    
    # è¿è¡Œæµ‹è¯•
    success = test_agent_with_real_env()
    
    if success:
        print("\n" + "ğŸ‰"*30)
        print("æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
        print("Debug-Gym + rLLM + K8s å®Œå…¨å°±ç»ªï¼")
        print("ğŸ‰"*30 + "\n")
        print("ä¸‹ä¸€æ­¥:")
        print("  bash examples/debug_gym/train_swe_bench_k8s.sh")
        print()
    
    return success


if __name__ == "__main__":
    try:
        success = main()
        sys.exit(0 if success else 1)
    except KeyboardInterrupt:
        print("\n\nâš ï¸  æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
        sys.exit(1)
    except Exception as e:
        print(f"\n\nâŒ æœªé¢„æœŸçš„é”™è¯¯: {e}")
        traceback.print_exc()
        sys.exit(1)

